# MyPhoto 프로젝트 개발 및 기술 백서

## 1. 프로젝트 개요
**MyPhoto**는 인터넷 연결 없이 로컬 PC(Mac/Windows) 환경에서 작동하는 **개인용 AI 사진 정리 애플리케이션**입니다. 수만 장에 달하는 방대한 사진 보관함에서 '인물(People)', '음식(Food)', '기타(Misc)' 사진을 자동으로 식별하여 폴더별로 정리해줍니다.

이 프로젝트의 시작은 **"사진 정리가 너무 힘들다"는 아내의 말**이었습니다. 나도 개발자 인 것을 아내에게 다시금 증명해 보이기 위해, **주말 단 이틀**이라는 짧은 시간 안에 완성도 높은 앱을 만들어내겠다는 개인적인 목표가 있었습니다.

동시에 기술적으로는, **"코드를 단 한 줄도 직접 작성하지 않고, 오직 AI와의 대화(Vibe Coding)만으로 상용 수준의 서비스를 만들 수 있을까?"**라는 실험적인 도전에서 시작되었습니다.

2일간 48시간을 전부 개발에 쓴 것은 아닙니다. 주말 간 아침에 등산도 2번 다녀오고, 아이들과 카탄 보드게임도 하고, 사우나, 외식, 드라마 시청까지 했습니다. **바이브 코딩을 하면서 놀라운 생산성을 경험했습니다.**

*   **핵심 가치**: 100% 오프라인 처리(프라이버시 보호), 빠른 속도, 사용자 맞춤형 정밀 분류.
*   **기술 스택**: Electron, React, Python, TensorFlow, MediaPipe.
*   **Vibe Coding 도구**: Antigravity, Google Gemini 3 Pro.



---

## 2. 해결하고자 했던 문제 (Problem Statement)
*   **방대한 사진량**: 아이 둘을 키우면서 쌓인 수만 장의 방대한 사진을 수동으로 정리하는 것은 불가능에 가깝습니다.
*   **기존 도구의 한계**: 단순 날짜 정리는 쉽지만, "사람"이나 "음식" 사진만 따로 보고 싶은 니즈를 충족하지 못합니다.
*   **클라우드 동기화의 한계**: 구글포토나 아이클라우드는 대용량 사진 동기화 시 오류나 누락 등 관리의 어려움이 있으며, 개인 사진이 외부 서버로 전송되는 것에 대한 프라이버시 우려가 공존합니다.
*   **파일 혼합의 번거로움**: 사진 폴더에 동영상, 문서, 시스템 오류 파일 등이 뒤섞여 있어, 순수하게 사진만 골라내거나 동영상만 따로 모으는 작업이 매우 번거롭습니다.
*   **로컬 AI의 딜레마 (속도 vs 정확도)**: 정확도가 높은 대형 AI 모델(LLaVA 등)은 너무 느리고, 가벼운 모델(OpenCV)은 정확도가 떨어집니다.

---

## 3. 기술 발전 과정 (Evolution of Technology)
최적의 AI 엔진을 찾기 위해 다양한 기술을 실험하고 검증했습니다.

### Phase 1: 거대 언어 모델 (LLaVA) 도입
*   **시도**: 이미지 인식 기능이 있는 LLaVA (Large Language-and-Vision Assistant) 모델 사용.
*   **결과**: 정확도는 높았으나, 사진 1장 분석에 수 초~수십 초가 소요됨. 수천 장 정리에 부적합. (실패)

### Phase 2: 고전적 컴퓨터 비전 (OpenCV Haar Cascade)
*   **시도**: 속도를 위해 아주 가벼운 OpenCV 얼굴 인식 사용.
*   **결과**: 속도는 매우 빨랐으나, 나무나 구름 등을 사람 얼굴로 착각하는 '오탐지(False Positive)'가 심각함. (실패)

### Phase 3: 객체 감지 AI (SSD MobileNet V2)
*   **시도**: TensorFlow 기반의 경량화된 객체 감지 모델인 SSD MobileNet V2 도입.
*   **결과**: '사람'은 기가 막히게 잘 찾음. 하지만 COCO 데이터셋의 한계로 다양한 '음식'을 인식하지 못하고 'Misc(기타)'로 분류함.

### Phase 4: 이미지 분류 AI (MobileNet V3 ImageNet)
*   **시도**: 1,000가지 사물을 아는 ImageNet 모델 도입.
*   **결과**: '음식'은 잘 찾지만, 사람을 찾을 때 배경에 묻히거나 작은 얼굴을 놓치는 경우가 많음.

### Phase 5: 하이브리드 (Hybrid) 모델
*   **시도**: **[SSD (사람 담당)] + [ImageNet (음식 담당)]** 두 모델을 동시에 실행.
*   **결과**: 사람과 음식을 모두 잘 잡음. 하지만 가끔 "음식 사진 뒤에 있는 사람" 때문에 음식 사진이 인물 사진으로 잘못 분류되거나 그 반대의 경우가 발생.

### Phase 6: 온디바이스 AI 최적화 (MediaPipe + MobileNet V3) - **최종 완성형**
*   **전환 배경**: 무거운 딥러닝 모델 대신, 구글의 최신 온디바이스 솔루션인 **MediaPipe**로 전면 교체.
*   **기술 스택**:
    1.  **Face Detection**: Google MediaPipe (0.70 임계값 최적화).
        *   **Hybrid Range**: 근거리(Selfie) 모델과 원거리(Full-range) 모델을 2중으로 돌려 빈틈없이 얼굴 포착.
    2.  **Context Analysis**: MobileNet V3 (ImageNet)
        *   사물, 음식, 풍경 등 1,000가지 컨텍스트 이해.
*   **고도화 로직 (V3 Hybrid Enhanced)**:
    *   **Safety Rule**: 얼굴이 감지되어도 배경이 '음식'이 확실하면(0.70 미만 신뢰도) 음식으로 분류 (오탐지 방지).
    *   **Rescue Rule**: 얼굴이 안 보여도 유모차, 아기띠, 놀이터 기구(그네) 등이 보이면 '사람'으로 구조 (미탐지 방지).
*   **성과**:
    *   초고속 처리 (장당 0.1~0.2초).
    *   난이도 높은 '아기 뒷모습', '놀이터 아이들', '식탁 위 음식' 구분 100% 성공.

---

## 4. 최종 시스템 아키텍처 (Smart Vision V3)

### 핵심 엔진: `Dual-Core Analysis Engine`
이 시스템은 "누구인가(Face)"와 "무엇인가(Context)"를 동시에 분석하여 교차 검증합니다.

1.  **Face Core (MediaPipe)**
    *   **역할**: 사진 속에서 '얼굴'의 특징점을 3D로 정요하게 추적.
    *   **전략**: 1차로 원거리 스캔 -> 실패 시 2차로 근거리 접사 스캔 (재시도 로직).
    *   **특징**: 안경, 마스크, 측면 얼굴에도 강건함.

2.  **Context Core (MobileNet V3)**
    *   **역할**: 사진의 전체적인 맥락을 읽음. (예: "이건 접시 위의 피자다", "이건 침대 위의 아기다")
    *   **특징**: 상위 5개 키워드를 추출하여 사람 관련 소품(유모차 등)이나 음식 관련 소품(접시 등)을 감지.

3.  **Decision Maker (심판관 로직)**
    *   두 엔진의 점수를 종합하여 최종 결정을 내립니다. '얼굴 점수' vs '음식 점수'를 경쟁시켜 더 확실한 쪽으로 분류합니다.

### 데이터 흐름
`[원본 사진]` -> `[MediaPipe (Face)]` + `[MobileNet (Context)]` -> `[Conflict Resolution (0.70 Cutoff)]` -> `[최종 분류]`

---

## 5. 성과 지표
*   **처리 속도**: 사진 100장 기준 약 15초 (매우 빠름).
*   **정확도**:
    *   **People**: 마스크 쓴 아이, 뒷모습, 놀이터 원거리 촬영까지 인식.
    *   **Food**: 사람 얼굴로 오인되기 쉬운 둥근 접시나 빵도 정확히 음식으로 분류.
*   **프라이버시**: 100% 로컬 처리 (인터넷 연결 불필요).

---

## 6. 주요 트러블슈팅 및 해결 사례 (Key Troubleshooting)
실제 수만 장의 사진을 테스트하며 겪은 대표적인 문제와 해결 과정입니다.

### Case 1: 근거리 셀카 미탐지 문제 (AI 모델의 사각지대)
*   **문제**: 단체 사진은 잘 찾는데, 스마트폰으로 찍은 '얼굴이 꽉 찬 셀카'를 인식하지 못하고 '기타'로 분류하는 현상 발생.
*   **원인**: 초기 사용한 MediaPipe 모델 설정이 '5미터 이상 원거리'에 최적화되어 있어, 너무 가까운 얼굴을 얼굴로 인식하지 못함.
*   **해결**: 1차로 원거리 모델을 돌리고, 실패 시 **근거리(Short-range) 모델**로 재스캔하는 **이중 안전장치(Fallback)** 구현. 이를 통해 셀카 인식률 100% 달성.

### Case 2: "아이들 밥 먹는 사진"의 딜레마 (컨텍스트 충돌)
*   **문제**: 아이들이 식탁 앞에 앉아있는 사진이 'People'이 아닌 'Food'로 분류됨.
*   **원인**: AI가 아이의 얼굴보다 식탁 위의 화려한 음식 정보를 더 강하게 인식함. (얼굴 점수 0.77 vs 음식 점수 0.90)
*   **해결**: **Conflict Resolution (충돌 해결)** 로직 정교화. "배경이 음식이더라도, 얼굴 신뢰도가 **0.70** 이상이면 무조건 사람으로 우선한다"는 규칙을 적용하여 해결.

### Case 3: 얼굴 없는 아이들 (뒷모습/배경)
*   **문제**: 얼굴이 보이지 않는 놀이터 뒷모습이나, 유모차에 타고 있는 사진이 '기타'로 버려짐.
*   **해결**: '얼굴(Face)' 감지에 실패하더라도, **MobileNet V3**가 감지한 사물이 `stroller`(유모차), `swing`(그네), `crib`(아기침대) 등 육아 용품이라면 **People**로 강제 구조(Rescue)하는 로직 추가.

### Case 4: 잡동사니 파일과 중복의 늪
*   **문제**: 사진 폴더에 숨어있던 `Thumbs.db`, `.MOV`, `설명서.pdf` 등이 섞여 정리가 엉망이 되고, 같은 사진이 여러 번 복사됨.
*   **해결**:
    1.  **Pre-Scan Filter**: 확장자를 분석하여 `Videos`, `Documents` 폴더로 자동 격리.
    2.  **Duplicate Skipper**: 내용이 동일한 중복 파일은 덮어쓰거나 지우지 않고 `Skipped` 처리하여 원본 보존 및 스토리지 낭비 방지.

---

## 7. 향후 발전 방향
*   **얼굴 클러스터링 UI**: 분류된 'People' 폴더 내에서 특정 인물(가족 구성원)별로 자동 앨범 생성 기능.
*   **자연어 검색**: "작년 여름 바닷가에서 찍은 사진" 처럼 말로 찾는 기능 (CLIP 도입 검토).
